# LLM Clientï¼ˆå¤§æ¨¡å‹å°åŠ©æ‰‹ï¼‰ğŸ¤–

**An ultra-simplistic, completely local, npm-based Ollama web interface developed with user experience in mind.**
**æç®€ Ollama æœ¬åœ°ç½‘é¡µç«¯ UI**

![Main UI](./pics/main-UI.png)

> [!TIP]  
> This project is still under development, and is meant to serve as a early-stage side-project for [Wanli-Go/Project-HILLM](https://github.com/Wanli-Go/Project-HILLM).

## Featuresï¼ˆåŠŸèƒ½ï¼‰

- **Ease of use**: clone the repo, run `npm install`, and run `npm run dev` to immediately use with your Ollama.
  - robust support for DeepSeek thinking models. ï¼ˆå®Œå…¨æ”¯æŒDeepSeekæ€è€ƒæ¨¡å¼ï¼‰
- **Simplistic, Satisfactory UI**: minimal configuration; strong focus on visual fluidness (with an option to reduce motion).
- **Accessibility:** use keyboard to navigate intuitively.
  - Press `Tab` to navigate between buttons.
  - Press `Ctrl + L` to open Settings.
- **Lightweight**: minimal dependencies (basic `vite` + `React` + `Typescript` + small packages like `prism.js` and `primeicons`)
  - Custom-written markdown renderer.
- **Language Support**: Chinese first, English second.ï¼ˆä¸­æ–‡ä¼˜å…ˆï¼‰

Give a star or make PRs if you like it!

## Installationï¼ˆå®‰è£…ï¼‰

***TL;DR**: pull models -> clone repo -> check out `.env` -> run `npm run dev`* 

- Install **Ollama** and **Node.js**, if you haven't already. ï¼ˆå®‰è£…Ollamaå’ŒNode.JSï¼‰

  - Ollama æ˜¯ä¸€ä¸ªåœ¨æœ¬åœ°éƒ¨ç½²å¤§æ¨¡å‹çš„ç®€å•ç¨‹åºã€‚
  - Node.js æ˜¯ä¸€ä¸ª JavaScript è¿è¡Œæ—¶ã€‚

- Use Ollama to pull at least 1 **DeepSeek model** and 1 **non-thinking model**. ï¼ˆç”¨Ollamaè·å–è‡³å°‘ä¸€ä¸ªDeepSeekæ¨¡å‹å’Œä¸€ä¸ªéæ€è€ƒæ¨¡å‹ï¼‰

  - [deepseek-r1](https://ollama.com/library/deepseek-r1)
  - éæ€è€ƒæ¨¡å‹ï¼Œå¦‚ [qwen2.5](https://ollama.com/library/qwen2.5) ï¼ˆé€šä¹‰åƒé—®2.5ï¼‰

- Clone the repo, navigate to project's folder, and run `npm install`. ï¼ˆå…‹éš†æœ¬ä»“åº“ï¼Œåœ¨å‘½ä»¤è¡Œä¸Šè¿›å…¥è¿™ä¸ªé¡¹ç›®çš„ç›®å½•ï¼Œç„¶åè¿è¡Œå®‰è£…æŒ‡ä»¤ `npm install`ï¼‰

- Configure `.env`: ï¼ˆè®¾ç½®é¡¹ç›®ç¯å¢ƒå˜é‡ï¼‰

  ![env](./pics/env.png)

  - `VITE_API_OLLAMA_URL`ï¼šOllama å¯¹è¯æ¥å£ï¼ˆé»˜è®¤ä¸º`http://localhost:11434/api/chat`ï¼‰
  - `VITE_THINKING_MODEL_NAME`ï¼šOllamaå®˜æ–¹æ¨¡å‹åç§°ï¼ˆDeepSeekï¼‰
  - `VITE_GENERAL_MODEL_NAME`ï¼šOllamaå®˜æ–¹éæ€è€ƒæ¨¡å‹åç§°

- run `npm run dev`. ï¼ˆåœ¨é¡¹ç›®ç›®å½•çš„å‘½ä»¤è¡Œä¸Šè¿è¡Œå‘½ä»¤å¯åŠ¨ç¨‹åºï¼‰

- Happy Hacking!

## Tips

- The project is still in her early stages.
- You can view the request body in browser's console every time you make a request.
- When you press the Regenerate button, it will use the input field's latest value, not last request's value.

## Showcase

![Thinking](./pics/thinking.png)

![Generating](./pics/generating.png)